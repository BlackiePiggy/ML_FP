# Flex Power End-to-End Causal Transformer (point-level) â€” Config
experiment_name: flexpower_causal_transformer

seed: 42
device: "cuda"  # "cuda" or "cpu"

# ==== Data ====
seq_len: 240        # e.g., 4 minutes @ 1 Hz; adapt to 30s sampling as needed
num_workers: 2
batch_size: 64
train_size: 20000   # synthetic size for demo; replace with your real dataset
val_size: 4000
test_size: 4000

# Feature dims
cont_features:
  - S1C_CN0
  - S2W_CN0
  - elevation
  - azimuth
  - dElev_dt
  - mask
num_cont: 6

# Categorical ids (IDs should be mapped to 0..n-1)
num_stations: 64
num_receivers: 64
num_antennas: 64
num_constellations: 4
num_prns: 64

# ==== Model ====
d_model: 128
n_heads: 4
n_layers: 3
dropout: 0.1
ffn_mult: 4
use_film: true      # Enable FiLM modulation by meta-embeddings
film_dim: 64

# ==== Optimization ====
lr: 0.0005
weight_decay: 0.01
epochs: 10
warmup_steps: 500

# ==== Loss ====
use_focal: true
focal_gamma: 2.0
pos_weight: 1.5

# ==== Eval ====
threshold: 0.5
